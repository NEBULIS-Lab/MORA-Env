{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### stat and visual"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed6733c9a074436"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in the dataset:\n",
      "KeysView(Frozen({'so': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'thetao': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'uo': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'vo': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'zos': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'utide': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'utotal': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'vtide': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'vtotal': <xarray.Variable (time: 720, depth: 1, latitude: 240, longitude: 240)> Size: 332MB\n",
      "[41472000 values with dtype=float64], 'elevation': <xarray.Variable (latitude: 240, longitude: 240)> Size: 230kB\n",
      "[57600 values with dtype=float32], 'time': <xarray.IndexVariable 'time' (time: 720)> Size: 6kB\n",
      "array(['2024-06-01T00:00:00.000000000', '2024-06-01T01:00:00.000000000',\n",
      "       '2024-06-01T02:00:00.000000000', ..., '2024-06-30T21:00:00.000000000',\n",
      "       '2024-06-30T22:00:00.000000000', '2024-06-30T23:00:00.000000000'],\n",
      "      dtype='datetime64[ns]'), 'depth': <xarray.IndexVariable 'depth' (depth: 1)> Size: 4B\n",
      "array([0.494025], dtype=float32), 'latitude': <xarray.IndexVariable 'latitude' (latitude: 240)> Size: 2kB\n",
      "array([33.      , 32.995816, 32.991632, ..., 32.008368, 32.004184, 32.      ]), 'longitude': <xarray.IndexVariable 'longitude' (longitude: 240)> Size: 2kB\n",
      "array([-66.5     , -66.495816, -66.491632, ..., -65.508368, -65.504184,\n",
      "       -65.5     ])}))\n",
      "\n",
      "Statistical Information:\n",
      "\n",
      "Variable: so\n",
      "  Min: 5076.4752\n",
      "  Max: 5149.4782\n",
      "  Mean: 5111.7744\n",
      "  Median: 5111.8149\n",
      "  Std: 11.4220\n",
      "\n",
      "Variable: thetao\n",
      "  Min: -278.9241\n",
      "  Max: -127.5963\n",
      "  Mean: -224.3536\n",
      "  Median: -230.7918\n",
      "  Std: 33.6354\n",
      "\n",
      "Variable: uo\n",
      "  Min: -20.6695\n",
      "  Max: 38.8348\n",
      "  Mean: 2.4012\n",
      "  Median: 1.5054\n",
      "  Std: 10.4744\n",
      "\n",
      "Variable: vo\n",
      "  Min: -17.0021\n",
      "  Max: 41.3878\n",
      "  Mean: 4.2406\n",
      "  Median: 4.0330\n",
      "  Std: 9.6978\n",
      "\n",
      "Variable: zos\n",
      "  Min: -282.8224\n",
      "  Max: -265.2470\n",
      "  Mean: -272.6160\n",
      "  Median: -271.8506\n",
      "  Std: 3.3524\n",
      "\n",
      "Variable: utide\n",
      "  Min: -10.0762\n",
      "  Max: 11.8166\n",
      "  Mean: 0.0325\n",
      "  Median: -0.2026\n",
      "  Std: 4.5840\n",
      "\n",
      "Variable: utotal\n",
      "  Min: -27.1662\n",
      "  Max: 38.4952\n",
      "  Mean: 2.2710\n",
      "  Median: 1.3403\n",
      "  Std: 12.0602\n",
      "\n",
      "Variable: vtide\n",
      "  Min: -6.7266\n",
      "  Max: 6.8326\n",
      "  Mean: 0.0133\n",
      "  Median: 0.0239\n",
      "  Std: 3.0189\n",
      "\n",
      "Variable: vtotal\n",
      "  Min: -28.1445\n",
      "  Max: 39.9217\n",
      "  Mean: 4.0882\n",
      "  Median: 4.3048\n",
      "  Std: 10.7546\n",
      "\n",
      "Variable: elevation\n",
      "  Min: -5121.0000\n",
      "  Max: -4043.0000\n",
      "  Mean: -4853.9580\n",
      "  Median: -4862.0000\n",
      "  Std: 87.6455\n",
      "\n",
      "Time Range:\n",
      "  Start Time: 2024-06-01T00:00:00.000000000\n",
      "  End Time: 2024-06-30T23:00:00.000000000\n",
      "  Time Span: 2588400000000000 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "nc_file = \"../MOPD_pipeline/Data/Combined/combined_environment.nc\"\n",
    "\n",
    "if not os.path.exists(nc_file):\n",
    "    raise FileNotFoundError(f\"File not found: {nc_file}\")\n",
    "\n",
    "dataset = xr.open_dataset(nc_file)\n",
    "\n",
    "print(\"Variables in the dataset:\")\n",
    "print(dataset.variables.keys())\n",
    "\n",
    "# statistics\n",
    "def compute_stats(var):\n",
    "    if var in [\"time\", \"depth\", \"latitude\", \"longitude\"]:\n",
    "        return None  # Skip non-numeric variables\n",
    "    \n",
    "    data = dataset[var].values.flatten()\n",
    "    data = data[~np.isnan(data)]  # Filter out NaN values\n",
    "    stats = {\n",
    "        \"Min\": np.min(data),\n",
    "        \"Max\": np.max(data),\n",
    "        \"Mean\": np.mean(data),\n",
    "        \"Median\": np.median(data),\n",
    "        \"Std\": np.std(data)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "stats_dict = {}\n",
    "for var in dataset.variables.keys():\n",
    "    stats = compute_stats(var)\n",
    "    if stats:\n",
    "        stats_dict[var] = stats\n",
    "\n",
    "print(\"\\nStatistical Information:\")\n",
    "for var, stats in stats_dict.items():\n",
    "    print(f\"\\nVariable: {var}\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Handle time variable\n",
    "if \"time\" in dataset.variables:\n",
    "    time_values = dataset[\"time\"].values\n",
    "    print(\"\\nTime Range:\")\n",
    "    print(f\"  Start Time: {time_values[0]}\")\n",
    "    print(f\"  End Time: {time_values[-1]}\")\n",
    "    print(f\"  Time Span: {time_values[-1] - time_values[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-23T00:13:34.982924Z",
     "start_time": "2025-03-23T00:13:30.967973Z"
    }
   },
   "id": "2ad91d6a180c93ac"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from visual import plot_3d_currents\n",
    "\n",
    "nc_file = \"../MOPD_pipeline/Data/Combined/combined_environment.nc\"\n",
    "dataset = xr.open_dataset(nc_file)\n",
    "\n",
    "plot_3d_currents(dataset, output_dir=\"output\", skip=20, arrow_size=0.05, arrow_height_offset=5, arrow_alpha=0.4, arrow_head_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-23T00:12:14.178447Z",
     "start_time": "2025-03-23T00:12:12.187832Z"
    }
   },
   "id": "eb30c04f5ad4b10f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, ConvLSTM2D, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nc_file = \"../MOPD_pipeline/Data/Combined/combined_environment.nc\"\n",
    "if not os.path.exists(nc_file):\n",
    "    raise FileNotFoundError(f\"File not found: {nc_file}\")\n",
    "dataset = xr.open_dataset(nc_file)\n",
    "data_uo = np.squeeze(dataset['uo'].values, axis=1)\n",
    "data_vo = np.squeeze(dataset['vo'].values, axis=1)\n",
    "data_uo_norm = (data_uo - np.mean(data_uo)) / np.std(data_uo)\n",
    "data_vo_norm = (data_vo - np.mean(data_vo)) / np.std(data_vo)\n",
    "data_stack = np.stack((data_uo_norm, data_vo_norm), axis=-1)\n",
    "\n",
    "test_mode = True\n",
    "if test_mode:\n",
    "    data_stack = data_stack[:20, :120, :120]\n",
    "    timesteps = 3\n",
    "else:\n",
    "    timesteps = 20\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(data_stack.shape[0] - timesteps):\n",
    "    X.append(data_stack[i:i + timesteps])\n",
    "    y.append(data_stack[i + timesteps])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "input_shape = (timesteps, X.shape[2], X.shape[3], X.shape[4])\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    ConvLSTM2D(8, (3, 3), padding='same', return_sequences=False, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(2, (3, 3), activation='linear', padding='same')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=1, verbose=1),\n",
    "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "epochs = 1 if test_mode else 10\n",
    "batch_size = 1 if test_mode else 8\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(X_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mse loss')\n",
    "plt.title('training history')\n",
    "plt.legend()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "sample_index = 0\n",
    "pred = model.predict(X_val)\n",
    "ground_truth = y_val[sample_index]\n",
    "prediction = pred[sample_index]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 6))\n",
    "channel_names = ['uo', 'vo']\n",
    "for i in range(2):\n",
    "    axes[i, 0].imshow(ground_truth[..., i], cmap='viridis')\n",
    "    axes[i, 0].set_title(f'ground truth {channel_names[i]}')\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(prediction[..., i], cmap='viridis')\n",
    "    axes[i, 1].set_title(f'prediction {channel_names[i]}')\n",
    "    axes[i, 1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_result.png')\n",
    "plt.show()\n",
    "\n",
    "model.save('final_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-23T03:03:02.829319Z"
    }
   },
   "id": "5c7295c45093ce82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, ConvLSTM2D, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        device = '/GPU:0'\n",
    "    except:\n",
    "        device = '/CPU:0'\n",
    "else:\n",
    "    device = '/CPU:0'\n",
    "\n",
    "nc_file = \"../MOPD_pipeline/Data/Combined/combined_environment.nc\"\n",
    "if not os.path.exists(nc_file):\n",
    "    raise FileNotFoundError(f\"File not found: {nc_file}\")\n",
    "dataset = xr.open_dataset(nc_file)\n",
    "data_uo = np.squeeze(dataset['uo'].values, axis=1)  # shape: (time, lat, lon)\n",
    "data_vo = np.squeeze(dataset['vo'].values, axis=1)  # shape: (time, lat, lon)\n",
    "\n",
    "# normalize\n",
    "data_uo_norm = (data_uo - np.mean(data_uo)) / np.std(data_uo)\n",
    "data_vo_norm = (data_vo - np.mean(data_vo)) / np.std(data_vo)\n",
    "data_stack = np.stack((data_uo_norm, data_vo_norm), axis=-1)  # shape: (time, lat, lon, 2)\n",
    "\n",
    "test_mode = False\n",
    "if test_mode:\n",
    "    data_stack = data_stack[:50]\n",
    "\n",
    "# construct sliding window samples\n",
    "timesteps = 10\n",
    "X, y = [], []\n",
    "for i in range(data_stack.shape[0] - timesteps):\n",
    "    X.append(data_stack[i:i+timesteps])\n",
    "    y.append(data_stack[i+timesteps])\n",
    "X = np.array(X)  # shape: (samples, timesteps, lat, lon, channels)\n",
    "y = np.array(y)  # shape: (samples, lat, lon, channels)\n",
    "\n",
    "# split data\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "# build ConvLSTM\n",
    "input_shape = (timesteps, X.shape[2], X.shape[3], X.shape[4])\n",
    "\n",
    "with tf.device(device):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        ConvLSTM2D(32, (3, 3), padding='same', return_sequences=True, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        ConvLSTM2D(32, (3, 3), padding='same', return_sequences=False, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(2, (3, 3), activation='linear', padding='same')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# set callbacks for training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1),\n",
    "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# training parameters\n",
    "epochs = 10 if not test_mode else 2\n",
    "batch_size = 8 if not test_mode else 4\n",
    "\n",
    "# train the model\n",
    "with tf.device(device):\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# visualize training history and save figure\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.savefig('training_history.png')  \n",
    "plt.show()\n",
    "\n",
    "sample_index = 0 \n",
    "with tf.device(device):\n",
    "    pred = model.predict(X_val)\n",
    "# pred shape: (samples, lat, lon, 2)  choose sample_index sample\n",
    "ground_truth = y_val[sample_index]\n",
    "prediction = pred[sample_index]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "channel_names = ['uo', 'vo']\n",
    "for i in range(2):\n",
    "    axes[i, 0].imshow(ground_truth[..., i], cmap='viridis')\n",
    "    axes[i, 0].set_title(f'ground truth {channel_names[i]}')\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(prediction[..., i], cmap='viridis')\n",
    "    axes[i, 1].set_title(f'prediction {channel_names[i]}')\n",
    "    axes[i, 1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_result.png') \n",
    "plt.show()\n",
    "\n",
    "# save the final model\n",
    "model.save('final_model.keras')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84d2b141bb07b9df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
